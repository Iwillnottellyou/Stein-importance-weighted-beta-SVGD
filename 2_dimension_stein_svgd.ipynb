{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNwobI2MKlFjQy6oTgwGEA+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Iwillnottellyou/Stein-importance-weighted-beta-SVGD/blob/main/2_dimension_stein_svgd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1D2tsxRL30F"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import numpy.matlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "\n",
        "\n",
        "def mirror_descent_heavy_ball(A,iter,stepsize,omega,alpha):\n",
        "    iter= iter\n",
        "    stepsize=stepsize\n",
        "    omega_m = omega\n",
        "    omegaold = omega\n",
        "    n = omega.shape[0]\n",
        "    for j in range(iter):\n",
        "        omega_m = omegaold\n",
        "        omegaold = omega\n",
        "        for i in range(n):\n",
        "          omega[i]=omega[i]*np.exp(-stepsize*np.matmul(A[i],omegaold)+alpha*(omegaold[i]-omega_m[i]))\n",
        "        omega = (1/omega.sum())*omega \n",
        "\n",
        "    return omega \n",
        "\n",
        "def mirror_descent_momentum(A,iter,stepsize,omega,alpha):\n",
        "    iter= iter\n",
        "    stepsize=stepsize\n",
        "    omega_m = omega\n",
        "    n = omega.shape[0]\n",
        "    for j in range(iter):\n",
        "        omega_m = alpha*omega_m + np.matmul(A,omega)\n",
        "        for i in range(n):\n",
        "          omega[i]=omega[i]*np.exp(-stepsize*omega_m[i])\n",
        "        omega = (1/omega.sum())*omega \n",
        "    print(np.matmul(np.matmul(A,omega),omega),sum(i<0.5 for i in n*omega)/n)\n",
        "\n",
        "    return omega \n",
        "\n",
        "class SVGD_model():\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "    def SVGD_kernal(self, x,beta, h=-1):\n",
        "        d = x.shape[1]\n",
        "        init_dist = pdist(x)\n",
        "        pairwise_dists = squareform(init_dist)\n",
        "        if h < 0:  # if h < 0, using median trick\n",
        "            h = np.median(pairwise_dists)\n",
        "            h = h ** 2 / np.log(x.shape[0] + 1)\n",
        "\n",
        "        kernal_xj_xi = np.exp(- pairwise_dists ** 2 / h)\n",
        "        d_kernal_xi = np.zeros([x.shape[0],d])\n",
        "        for i_index in range(x.shape[0]):\n",
        "            d_kernal_xi[i_index] = np.matmul(kernal_xj_xi[i_index], x[i_index] - x) * 2/h\n",
        "\n",
        "        if beta == 0:\n",
        "          return kernal_xj_xi, d_kernal_xi\n",
        "\n",
        "        else:\n",
        "          dd_kernal_xj_xi=np.zeros([x.shape[0],x.shape[0]])\n",
        "          dd_kernal_xj_xi= np.multiply(kernal_xj_xi,2*d/h-4*pairwise_dists**2/h**2)\n",
        "\n",
        "        return kernal_xj_xi, d_kernal_xi,dd_kernal_xj_xi, h\n",
        "\n",
        "    def update(self, x0, lnprob,probdensity,beta, n_iter=1000, stepsize=1e-3,opt_step = 1,opt_iter=20, bandwidth=-1, debug=False,alpha=0.5,optimization_choice=1,init_iter=1000):\n",
        "        # Check input\n",
        "        if x0 is None or lnprob is None:\n",
        "            raise ValueError('x0 or lnprob cannot be None!')\n",
        "\n",
        "        x = np.copy(x0)\n",
        "        n = x.shape[0]\n",
        "        omega = 1/n*np.ones(n)\n",
        "        d_kernal_times_score = np.zeros([n,n])\n",
        "        # adagrad with momentum\n",
        "        for iter in range(n_iter):\n",
        "            if debug and (iter + 1) % 1000 == 0:\n",
        "                print('iter ' + str(iter + 1))\n",
        "            gradmatrix = lnprob(x)\n",
        "\n",
        "            if beta==0:\n",
        "              kernal_xj_xi, d_kernal_xi = self.SVGD_kernal(x,0, bandwidth)\n",
        "              current_grad = (np.matmul(kernal_xj_xi, gradmatrix) + d_kernal_xi) / n\n",
        "              x += stepsize * current_grad\n",
        "              print('iter:',iter,x.sum(0)/x.shape[0])\n",
        "              if iter == n_iter-1:\n",
        "                kernal_xj_xi, d_kernal_xi,dd_kernal_xj_xi, h = self.SVGD_kernal(x,-0.5, bandwidth)\n",
        "\n",
        "                for i_index in range(n):\n",
        "                  d_kernal_times_score[i_index] = np.matmul(gradmatrix[i_index],(x[i_index]-x).transpose())\n",
        "                \n",
        "                d_kernal_times_score = (d_kernal_times_score+d_kernal_times_score.transpose())*(2/h)\n",
        "\n",
        "                SteinMatrix = np.multiply(kernal_xj_xi,np.matmul(gradmatrix,gradmatrix.transpose()))\\\n",
        "                +dd_kernal_xj_xi+d_kernal_times_score\n",
        "\n",
        "                if optimization_choice == 1:\n",
        "                  omega = mirror_descent_heavy_ball(SteinMatrix,init_iter,opt_step,omega,alpha) \n",
        "                if optimization_choice == 2:\n",
        "                  omega = mirror_descent_momentum(SteinMatrix,init_iter,opt_step,omega,alpha) \n",
        "            else:\n",
        "              if iter%40 ==0 or iter <=5 or iter == n_iter-1:\n",
        "                kernal_xj_xi, d_kernal_xi,dd_kernal_xj_xi,h = self.SVGD_kernal(x,beta, bandwidth)\n",
        "\n",
        "                for i_index in range(n):\n",
        "                  d_kernal_times_score[i_index] = np.matmul(gradmatrix[i_index],(x[i_index]-x).transpose())\n",
        "                \n",
        "                d_kernal_times_score = np.multiply((d_kernal_times_score+d_kernal_times_score.transpose())*(2/h),kernal_xj_xi)\n",
        "\n",
        "                SteinMatrix = np.multiply(kernal_xj_xi,np.matmul(gradmatrix,gradmatrix.transpose()))\\\n",
        "                +dd_kernal_xj_xi+d_kernal_times_score\n",
        "                if iter <1:\n",
        "                  if optimization_choice == 1:\n",
        "                    omega = mirror_descent_heavy_ball(SteinMatrix,init_iter,opt_step,omega,alpha) \n",
        "                  if optimization_choice == 2:\n",
        "                    omega = mirror_descent_momentum(SteinMatrix,init_iter,opt_step,omega,alpha)\n",
        "\n",
        "                if iter == n_iter-1:\n",
        "                  if optimization_choice == 1:\n",
        "                    omega = mirror_descent_heavy_ball(SteinMatrix,init_iter,opt_step,omega,alpha) \n",
        "                  if optimization_choice == 2:\n",
        "                    omega = mirror_descent_momentum(SteinMatrix,init_iter,opt_step,omega,alpha)\n",
        "                else:\n",
        "                  if optimization_choice == 1:\n",
        "                    omega = mirror_descent_heavy_ball(SteinMatrix,opt_iter,opt_step,omega,alpha) \n",
        "                  if optimization_choice == 2:\n",
        "                    omega = mirror_descent_momentum(SteinMatrix,opt_iter,opt_step,omega,alpha) \n",
        "              else:\n",
        "                kernal_xj_xi, d_kernal_xi = self.SVGD_kernal(x,0, bandwidth)\n",
        "\n",
        "\n",
        "              current_grad = np.multiply(np.mat((n*omega+0.0001)**(beta)).transpose(),(np.matmul(kernal_xj_xi, gradmatrix) + d_kernal_xi)) / n\n",
        "              x += stepsize * current_grad\n",
        "              print('iter:',iter,x.sum(0)/x.shape[0])\n",
        "        return x,omega\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "sns.set_palette('deep', desat=.6)\n",
        "sns.set_context(rc={'figure.figsize': (8, 5) } )\n",
        "\n",
        "\n",
        "class highDimensionGM():\n",
        "\n",
        "    def __init__(self, dimension,omega, mean, var):\n",
        "        self.dimension = dimension\n",
        "        self.omega = omega\n",
        "        self.mean = mean\n",
        "        self.var = var\n",
        "\n",
        "    def dlnprob(self, x):\n",
        "\n",
        "        rep_x = np.tile(np.expand_dims(x,axis=1),(1,w.shape[0],1))\n",
        "        category_prob = np.exp(- np.linalg.norm(rep_x-self.mean,axis=2)**2 / (2 * self.var)) / ((2 * np.pi * self.var)**(self.dimension/2)) * self.omega\n",
        "        den = np.expand_dims(np.sum(category_prob, 1),axis=1)\n",
        "        num = -(np.tile(np.expand_dims(category_prob,axis=2),(1,1,x.shape[1]))*(rep_x - self.mean)).sum(1)\n",
        "        return num/den\n",
        "\n",
        "    def MGprob(self, x):\n",
        "        rep_x = np.tile(np.expand_dims(x,axis=1),(1,w.shape[0],1))\n",
        "        category_prob = np.exp(- np.linalg.norm(rep_x-self.mean,axis=2)**2 / (2 * self.var)) / ((2 * np.pi * self.var)**(self.dimension/2)) * self.omega\n",
        "        den = np.sum(category_prob,1)\n",
        "        return np.expand_dims(den,1)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    dimension =2\n",
        "    w = np.array([0.4,0.6])\n",
        "    mean = np.array([[2 for i in range(dimension)],[0.5 for i in range(dimension)]])\n",
        "    var = np.array([1,1])\n",
        "\n",
        "    highDimensionGM_model = highDimensionGM(dimension,w, mean, var)\n",
        "\n",
        "    np.random.seed(0)\n",
        "    num_particle = 1000\n",
        "    x0 = np.random.normal(0, 2, [num_particle,dimension]);\n",
        "    dlnprob = highDimensionGM_model.dlnprob\n",
        "    probdensity=highDimensionGM_model.MGprob\n",
        "\n",
        "    svgd_model = SVGD_model()\n",
        "    n_iter = 10000\n",
        "    beta =-0.5\n",
        "   \n",
        "    x,omega = svgd_model.update(x0, dlnprob, probdensity, beta, n_iter=n_iter, stepsize=1,opt_step = 20, opt_iter=200, bandwidth=-1, debug=True,alpha=0.2,optimization_choice=2\\\n",
        "                                ,init_iter=1000)\n",
        "    #biggest stepsize=1.9\n",
        "    # print((x*x).sum(1).sum(0)/num_particle)\n",
        "    # print(np.matmul((x*x).sum(1),omega))#x^2 average value is 24.2, x average value is 4.4\n",
        "    print(x.sum(1).sum(0)/num_particle)\n",
        "    print(np.matmul(x.sum(1),omega))\n",
        "\n",
        "    #plot result\n",
        "    sns.kdeplot(x.reshape((num_particle,)), bw = .4, color = 'g')\n",
        "\n",
        "    mg_prob = highDimensionGM_model.MGprob\n",
        "    x_lin = np.expand_dims(np.linspace(-15, 15, 100), 1)\n",
        "    x_prob = mg_prob(x_lin)\n",
        "    plt.plot(x_lin, x_prob, 'b--')\n",
        "    plt.axis([-15, 15, 0, 0.4])\n",
        "    plt.title(str(n_iter) + '$ ^{th}$ iteration, '+'beta='+str(beta))\n",
        "    plt.show()\n",
        "\n",
        "#iter=20, out_stepsize=0.5, inner_stepsize=5,inner_iter=100 achieve very good results.\n",
        "\n",
        "#iter=500, stepsize=1.1,inner_stepsize=5,inner_iter=20 is stable than 0-SVGD with stepsize=11, \\\n",
        "#while when stepsize=12 for SVGD(it will diverge) and stepsize=1.2 for stein -0.5-SVGD(converge)\n",
        "#200 particle,when stepsize=1 for stein -0.5-SVGD , 500 iterations,it can produce nice results, but for SVGD with stepsize=10, the result is bad\n",
        "#100 particles, step=0.9 for stein SVGD 100 iterations better than SVGD with step=9 and iter=100(SVGD is not stable, more iterations will make the results worse） \n"
      ]
    }
  ]
}